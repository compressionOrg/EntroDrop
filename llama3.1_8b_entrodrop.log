layers_order="29,30,28,26,18,16,17,24,6,20,22,4,19,15,25,27,23,7,8,0,3,13,10,5,14,21,1,12,2,9,11,31"


+ echo 'Running with num_prune=4'
2025-07-21 09:11:16,246 - evaluate_grasp - INFO - wikitext2 35.03701400756836
2025-07-21 09:11:16,246 - evaluate_grasp - INFO - load dataset ptb
100%|███████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:14<00:00,  2.94it/s]
2025-07-21 09:11:30,860 - evaluate_grasp - INFO - ptb 52.918338775634766
  0%|                                                                                                     | 0/83947 [00:00<?, ?it/s]
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be F
P32)
100%|███████████████████████████████████████████████████████████████████████████████████████| 83947/83947 [1:25:18<00:00, 16.40it/s]
2025-07-21 10:38:21,258 - evaluate_grasp - INFO - {'wikitext2': 35.03701400756836, 'ptb': 52.918338775634766, 'mathqa': {'acc': 0.33
06532663316583, 'acc_stderr': 0.008612169591864846, 'acc_norm': 0.33869346733668343, 'acc_norm_stderr': 0.008663739930566804}, 'piqa
': {'acc': 0.7257889009793254, 'acc_stderr': 0.010408618664933379, 'acc_norm': 0.73449401523395, 'acc_norm_stderr': 0.01030330865302
443}, 'hellaswag': {'acc': 0.40908185620394344, 'acc_stderr': 0.004906595857916754, 'acc_norm': 0.5597490539733121, 'acc_norm_stderr
': 0.004954026775425769}, 'winogrande': {'acc': np.float64(0.6464088397790055), 'acc_stderr': 0.013436541262599954}, 'arc_easy': {'a
cc': 0.6127946127946128, 'acc_stderr': 0.009995312065890351, 'acc_norm': 0.5921717171717171, 'acc_norm_stderr': 0.010083950240041214
}, 'arc_challenge': {'acc': 0.38822525597269625, 'acc_stderr': 0.014241614207414028, 'acc_norm': 0.4087030716723549, 'acc_norm_stder
r': 0.014365750345427006}, 'openbookqa': {'acc': 0.294, 'acc_stderr': 0.020395095484936607, 'acc_norm': 0.398, 'acc_norm_stderr': 0.
021912377885779967}, 'boolq': {'acc': 0.6220183486238532, 'acc_stderr': 0.008480656964585243}, 'mean': np.float64(0.5036213850856369
)}
2025-07-21 10:38:21,260 - evaluate_grasp - INFO -

===== mean acc: 0.5036213850856369 =====

+ echo 'Running with num_prune=8'
+ python run_rm_layers.py --layers_to_remove 29,30,28,26,18,16,17,24,6,20,22,4,19,15,25,27,23,7,8,0,3,13,10,5,14,21,1,12,2,9,11,31 -
-num_prune 8
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.28s/it]
2025-07-21 10:38:33,439 - evaluate_grasp - INFO - load dataset wikitext2
Token indices sequence length is longer than the specified maximum sequence length for this model (289077 > 131072). Running this se
quence through the model will result in indexing errors
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 141/141 [01:43<00:00,  1.36it/s]
2025-07-21 10:40:18,423 - evaluate_grasp - INFO - wikitext2 72.45914459228516
2025-07-21 10:40:18,423 - evaluate_grasp - INFO - load dataset ptb
100%|███████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:33<00:00,  1.26it/s]
2025-07-21 10:40:52,040 - evaluate_grasp - INFO - ptb 84.53182220458984 
  0%|                                                                                                     | 0/83947 [00:00<?, ?it/s]
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be F
P32)
100%|███████████████████████████████████████████████████████████████████████████████████████| 83947/83947 [1:17:22<00:00, 18.08it/s]
2025-07-21 11:59:58,385 - evaluate_grasp - INFO - {'wikitext2': 72.45914459228516, 'ptb': 84.53182220458984, 'mathqa': {'acc': 0.253
9363484087102, 'acc_stderr': 0.007968030108429303, 'acc_norm': 0.2646566164154104, 'acc_norm_stderr': 0.00807582804382805}, 'piqa':
{'acc': 0.6877040261153428, 'acc_stderr': 0.010812581599154424, 'acc_norm': 0.6942328618063112, 'acc_norm_stderr': 0.010749627366141
632}, 'hellaswag': {'acc': 0.3988249352718582, 'acc_stderr': 0.0048865590087549884, 'acc_norm': 0.5321649073889664, 'acc_norm_stderr
': 0.004979446038824758}, 'winogrande': {'acc': np.float64(0.65982636148382), 'acc_stderr': 0.013315218762417399}, 'arc_easy': {'acc
': 0.5370370370370371, 'acc_stderr': 0.010231597249131053, 'acc_norm': 0.5138888888888888, 'acc_norm_stderr': 0.010255824507190345},
 'arc_challenge': {'acc': 0.3378839590443686, 'acc_stderr': 0.01382204792228351, 'acc_norm': 0.35580204778157, 'acc_norm_stderr': 0.
01399057113791876}, 'openbookqa': {'acc': 0.24, 'acc_stderr': 0.019118866653759736, 'acc_norm': 0.344, 'acc_norm_stderr': 0.02126575
803797874}, 'boolq': {'acc': 0.6211009174311927, 'acc_stderr': 0.008484678718565017}, 'mean': np.float64(0.46703919809904115)}
2025-07-21 11:59:58,386 - evaluate_grasp - INFO -

===== mean acc: 0.46703919809904115 =====

2025-07-21 12:00:09,922 - evaluate_grasp - INFO - load dataset wikitext2
Token indices sequence length is longer than the specified maximum sequence length for this model (289077 > 131072). Running this se
quence through the model will result in indexing errors
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 141/141 [01:30<00:00,  1.57it/s]
2025-07-21 12:01:40,909 - evaluate_grasp - INFO - wikitext2 322.00701904296875
2025-07-21 12:01:40,909 - evaluate_grasp - INFO - load dataset ptb
100%|███████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:28<00:00,  1.48it/s]
2025-07-21 12:02:09,580 - evaluate_grasp - INFO - ptb 300.58465576171875
  0%|                                                                                                     | 0/83947 [00:00<?, ?it/s]
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be F
P32)
100%|███████████████████████████████████████████████████████████████████████████████████████| 83947/83947 [1:07:44<00:00, 20.66it/s]
2025-07-21 13:11:29,774 - evaluate_grasp - INFO - {'wikitext2': 322.00701904296875, 'ptb': 300.58465576171875, 'mathqa': {'acc': 0.2
1909547738693466, 'acc_stderr': 0.007572098697066916, 'acc_norm': 0.23417085427135678, 'acc_norm_stderr': 0.007752342577747439}, 'pi
qa': {'acc': 0.6213275299238302, 'acc_stderr': 0.011317163404516847, 'acc_norm': 0.6186071817192601, 'acc_norm_stderr': 0.0113328504
0652868}, 'hellaswag': {'acc': 0.33419637522405893, 'acc_stderr': 0.004707447244200626, 'acc_norm': 0.4062935670185222, 'acc_norm_st
derr': 0.0049013686295334155}, 'winogrande': {'acc': np.float64(0.5880031570639306), 'acc_stderr': 0.013833112857645928}, 'arc_easy'
: {'acc': 0.42508417508417506, 'acc_stderr': 0.010143966195717842, 'acc_norm': 0.38762626262626265, 'acc_norm_stderr': 0.00999730791
4447608}, 'arc_challenge': {'acc': 0.23464163822525597, 'acc_stderr': 0.012383873560768668, 'acc_norm': 0.26535836177474403, 'acc_no
rm_stderr': 0.012902554762313966}, 'openbookqa': {'acc': 0.204, 'acc_stderr': 0.018039369104138663, 'acc_norm': 0.292, 'acc_norm_std
err': 0.020354375480530082}, 'boolq': {'acc': 0.5155963302752293, 'acc_stderr': 0.008740799550176545}, 'mean': np.float64(0.39274308
53979269)}
2025-07-21 13:11:29,776 - evaluate_grasp - INFO -

===== mean acc: 0.3927430853979269 =====


+ python run_rm_layers.py --layers_to_remove 29,30,28,26,18,16,17,24,6,20,22,4,19,15,25,27,23,7,8,0,3,13,10,5,14,21,1,12,2,9,11,31 -
-num_prune 16
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.37s/it]
2025-07-21 13:11:41,383 - evaluate_grasp - INFO - load dataset wikitext2
Token indices sequence length is longer than the specified maximum sequence length for this model (289077 > 131072). Running this se
quence through the model will result in indexing errors
100%|█████████████████████████████████████████████████████████████████████████████████████████████| 141/141 [01:05<00:00,  2.15it/s]
2025-07-21 13:12:48,054 - evaluate_grasp - INFO - wikitext2 18591.869140625
2025-07-21 13:12:48,054 - evaluate_grasp - INFO - load dataset ptb
100%|███████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:22<00:00,  1.90it/s]
2025-07-21 13:13:10,390 - evaluate_grasp - INFO - ptb 10137.1171875
  0%|                                                                                                     | 0/83947 [00:00<?, ?it/s]
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be F
P32)
100%|███████████████████████████████████████████████████████████████████████████████████████| 83947/83947 [1:00:06<00:00, 23.28it/s]
2025-07-21 14:15:23,322 - evaluate_grasp - INFO - {'wikitext2': 18591.869140625, 'ptb': 10137.1171875, 'mathqa': {'acc': 0.193969849
24623115, 'acc_stderr': 0.007238412826802101, 'acc_norm': 0.20402010050251257, 'acc_norm_stderr': 0.0073771416005697235}, 'piqa': {'
acc': 0.5174102285092492, 'acc_stderr': 0.011658749823107691, 'acc_norm': 0.5054406964091404, 'acc_norm_stderr': 0.01166513350063706
}, 'hellaswag': {'acc': 0.23471420035849433, 'acc_stderr': 0.004229538929090428, 'acc_norm': 0.20274845648277234, 'acc_norm_stderr':
 0.004012249939174915}, 'winogrande': {'acc': np.float64(0.526440410418311), 'acc_stderr': 0.014032823874407225}, 'arc_easy': {'acc'
: 0.2718855218855219, 'acc_stderr': 0.009129795867310496, 'acc_norm': 0.27525252525252525, 'acc_norm_stderr': 0.009164888895174743},
 'arc_challenge': {'acc': 0.21928327645051193, 'acc_stderr': 0.012091245787615725, 'acc_norm': 0.25341296928327645, 'acc_norm_stderr
': 0.012710896778378606}, 'openbookqa': {'acc': 0.164, 'acc_stderr': 0.016575811142446686, 'acc_norm': 0.28, 'acc_norm_stderr': 0.02
0099950647503237}, 'boolq': {'acc': 0.5434250764525994, 'acc_stderr': 0.008712010793695305}, 'mean': np.float64(0.3338910704151149)}
2025-07-21 14:15:23,324 - evaluate_grasp - INFO -

===== mean acc: 0.3338910704151149 =====2025-07-22 21:03:02,048 - __main__ - INFO - Loading model: meta-llama/Llama-3.1-8B
2025-07-22 21:03:11,438 - __main__ - INFO - Layers order: 29,30,28,26,18,16,17,24,6,20,22,4,19,15,25,27,23,7,8,0,3,13,10,5,14,21,1,12,2,9,11,31
2025-07-22 21:03:11,438 - __main__ - INFO - Num prune: 4
2025-07-22 21:03:11,439 - __main__ - INFO - Layers to remove: [29, 30, 28, 26]
2025-07-22 21:03:11,439 - __main__ - INFO - ====================================================================================================
2025-07-22 21:03:11,442 - evaluate_grasp - INFO - load dataset wikitext2
2025-07-22 21:03:59,353 - evaluate_grasp - INFO - wikitext2 35.03701400756836
2025-07-22 21:03:59,353 - evaluate_grasp - INFO - load dataset ptb
2025-07-22 21:04:13,973 - evaluate_grasp - INFO - ptb 52.918338775634766
2025-07-22 23:40:16,127 - evaluate_grasp - INFO - {'wikitext2': 35.03701400756836, 'ptb': 52.918338775634766, 'mathqa': {'acc': 0.3306532663316583, 'acc_stderr': 0.008612169591864846, 'acc_norm': 0.33869346733668343, 'acc_norm_stderr': 0.008663739930566804}, 'piqa': {'acc': 0.7257889009793254, 'acc_stderr': 0.010408618664933379, 'acc_norm': 0.73449401523395, 'acc_norm_stderr': 0.01030330865302443}, 'hellaswag': {'acc': 0.40908185620394344, 'acc_stderr': 0.004906595857916754, 'acc_norm': 0.5597490539733121, 'acc_norm_stderr': 0.004954026775425769}, 'winogrande': {'acc': np.float64(0.6464088397790055), 'acc_stderr': 0.013436541262599954}, 'arc_easy': {'acc': 0.6127946127946128, 'acc_stderr': 0.009995312065890351, 'acc_norm': 0.5921717171717171, 'acc_norm_stderr': 0.010083950240041214}, 'arc_challenge': {'acc': 0.38822525597269625, 'acc_stderr': 0.014241614207414028, 'acc_norm': 0.4087030716723549, 'acc_norm_stderr': 0.014365750345427006}, 'openbookqa': {'acc': 0.294, 'acc_stderr': 0.020395095484936607, 'acc_norm': 0.398, 'acc_norm_stderr': 0.021912377885779967}, 'boolq': {'acc': 0.6220183486238532, 'acc_stderr': 0.008480656964585243}, 'mean': np.float64(0.5036213850856369)}
2025-07-22 23:40:16,128 - evaluate_grasp - INFO - 

===== mean acc: 0.5036213850856369 =====


2025-07-22 23:40:20,314 - __main__ - INFO - Loading model: meta-llama/Llama-3.1-8B
2025-07-22 23:40:41,146 - __main__ - INFO - Layers order: 29,30,28,26,18,16,17,24,6,20,22,4,19,15,25,27,23,7,8,0,3,13,10,5,14,21,1,12,2,9,11,31
2025-07-22 23:40:41,146 - __main__ - INFO - Num prune: 6
2025-07-22 23:40:41,146 - __main__ - INFO - Layers to remove: [29, 30, 28, 26, 18, 16]
2025-07-22 23:40:41,146 - __main__ - INFO - ====================================================================================================
2025-07-22 23:40:41,148 - evaluate_grasp - INFO - load dataset wikitext2
2025-07-22 23:42:56,974 - evaluate_grasp - INFO - wikitext2 51.981849670410156
2025-07-22 23:42:56,974 - evaluate_grasp - INFO - load dataset ptb
2025-07-22 23:43:26,668 - evaluate_grasp - INFO - ptb 68.47189331054688
2025-07-23 01:36:01,210 - evaluate_grasp - INFO - {'wikitext2': 51.981849670410156, 'ptb': 68.47189331054688, 'mathqa': {'acc': 0.2663316582914573, 'acc_stderr': 0.008092111847754038, 'acc_norm': 0.271356783919598, 'acc_norm_stderr': 0.008140074791264346}, 'piqa': {'acc': 0.705658324265506, 'acc_stderr': 0.010633311470347507, 'acc_norm': 0.7236126224156693, 'acc_norm_stderr': 0.01043416238827561}, 'hellaswag': {'acc': 0.41326428998207526, 'acc_stderr': 0.0049141308554317776, 'acc_norm': 0.5667197769368651, 'acc_norm_stderr': 0.004945157565218195}, 'winogrande': {'acc': np.float64(0.6582478295185478), 'acc_stderr': 0.013330103018622868}, 'arc_easy': {'acc': 0.5757575757575758, 'acc_stderr': 0.010141333654958564, 'acc_norm': 0.5547138047138047, 'acc_norm_stderr': 0.010198171137873866}, 'arc_challenge': {'acc': 0.3583617747440273, 'acc_stderr': 0.014012883334859866, 'acc_norm': 0.38310580204778155, 'acc_norm_stderr': 0.014206472661672883}, 'openbookqa': {'acc': 0.294, 'acc_stderr': 0.020395095484936614, 'acc_norm': 0.394, 'acc_norm_stderr': 0.021874299301689257}, 'boolq': {'acc': 0.6134556574923548, 'acc_stderr': 0.00851694393434197}, 'mean': np.float64(0.485634638756443)}
2025-07-23 01:36:01,214 - evaluate_grasp - INFO - 

===== mean acc: 0.485634638756443 =====


2025-07-23 01:36:06,153 - __main__ - INFO - Loading model: meta-llama/Llama-3.1-8B
2025-07-23 01:36:14,328 - __main__ - INFO - Layers order: 29,30,28,26,18,16,17,24,6,20,22,4,19,15,25,27,23,7,8,0,3,13,10,5,14,21,1,12,2,9,11,31
2025-07-23 01:36:14,328 - __main__ - INFO - Num prune: 8
2025-07-23 01:36:14,329 - __main__ - INFO - Layers to remove: [29, 30, 28, 26, 18, 16, 17, 24]
2025-07-23 01:36:14,329 - __main__ - INFO - ====================================================================================================
2025-07-23 01:36:14,331 - evaluate_grasp - INFO - load dataset wikitext2
2025-07-23 01:38:46,627 - evaluate_grasp - INFO - wikitext2 72.45914459228516
2025-07-23 01:38:46,627 - evaluate_grasp - INFO - load dataset ptb
2025-07-23 01:39:13,466 - evaluate_grasp - INFO - ptb 84.53182220458984
2025-07-23 03:29:10,609 - evaluate_grasp - INFO - {'wikitext2': 72.45914459228516, 'ptb': 84.53182220458984, 'mathqa': {'acc': 0.2539363484087102, 'acc_stderr': 0.007968030108429303, 'acc_norm': 0.2646566164154104, 'acc_norm_stderr': 0.00807582804382805}, 'piqa': {'acc': 0.6877040261153428, 'acc_stderr': 0.010812581599154424, 'acc_norm': 0.6942328618063112, 'acc_norm_stderr': 0.010749627366141632}, 'hellaswag': {'acc': 0.3988249352718582, 'acc_stderr': 0.0048865590087549884, 'acc_norm': 0.5321649073889664, 'acc_norm_stderr': 0.004979446038824758}, 'winogrande': {'acc': np.float64(0.65982636148382), 'acc_stderr': 0.013315218762417399}, 'arc_easy': {'acc': 0.5370370370370371, 'acc_stderr': 0.010231597249131053, 'acc_norm': 0.5138888888888888, 'acc_norm_stderr': 0.010255824507190345}, 'arc_challenge': {'acc': 0.3378839590443686, 'acc_stderr': 0.01382204792228351, 'acc_norm': 0.35580204778157, 'acc_norm_stderr': 0.01399057113791876}, 'openbookqa': {'acc': 0.24, 'acc_stderr': 0.019118866653759736, 'acc_norm': 0.344, 'acc_norm_stderr': 0.02126575803797874}, 'boolq': {'acc': 0.6211009174311927, 'acc_stderr': 0.008484678718565017}, 'mean': np.float64(0.46703919809904115)}
2025-07-23 03:29:10,610 - evaluate_grasp - INFO - 

===== mean acc: 0.46703919809904115 =====


2025-07-23 03:29:14,566 - __main__ - INFO - Loading model: meta-llama/Llama-3.1-8B
2025-07-23 03:29:23,554 - __main__ - INFO - Layers order: 29,30,28,26,18,16,17,24,6,20,22,4,19,15,25,27,23,7,8,0,3,13,10,5,14,21,1,12,2,9,11,31
2025-07-23 03:29:23,554 - __main__ - INFO - Num prune: 10
2025-07-23 03:29:23,555 - __main__ - INFO - Layers to remove: [29, 30, 28, 26, 18, 16, 17, 24, 6, 20]
2025-07-23 03:29:23,555 - __main__ - INFO - ====================================================================================================
2025-07-23 03:29:23,557 - evaluate_grasp - INFO - load dataset wikitext2
2025-07-23 03:30:59,150 - evaluate_grasp - INFO - wikitext2 113.79232025146484
2025-07-23 03:30:59,150 - evaluate_grasp - INFO - load dataset ptb
2025-07-23 03:31:28,411 - evaluate_grasp - INFO - ptb 129.97906494140625
2025-07-23 05:13:31,237 - evaluate_grasp - INFO - {'wikitext2': 113.79232025146484, 'ptb': 129.97906494140625, 'mathqa': {'acc': 0.22244556113902847, 'acc_stderr': 0.0076133862785359085, 'acc_norm': 0.23919597989949748, 'acc_norm_stderr': 0.007809332748857688}, 'piqa': {'acc': 0.6566920565832427, 'acc_stderr': 0.011078175207348832, 'acc_norm': 0.6664853101196954, 'acc_norm_stderr': 0.01100013959218457}, 'hellaswag': {'acc': 0.38169687313284206, 'acc_stderr': 0.0048480996616196825, 'acc_norm': 0.5020912168890659, 'acc_norm_stderr': 0.0049897377687499415}, 'winogrande': {'acc': np.float64(0.6227308602999211), 'acc_stderr': 0.0136225679287995}, 'arc_easy': {'acc': 0.4621212121212121, 'acc_stderr': 0.010230299628864802, 'acc_norm': 0.44907407407407407, 'acc_norm_stderr': 0.010206428316323363}, 'arc_challenge': {'acc': 0.26706484641638223, 'acc_stderr': 0.012928933196496357, 'acc_norm': 0.310580204778157, 'acc_norm_stderr': 0.01352229209805305}, 'openbookqa': {'acc': 0.23, 'acc_stderr': 0.01883905039112313, 'acc_norm': 0.322, 'acc_norm_stderr': 0.02091666833001988}, 'boolq': {'acc': 0.6223241590214067, 'acc_stderr': 0.00847930920828165}, 'mean': np.float64(0.4331344460892544)}
2025-07-23 05:13:31,239 - evaluate_grasp - INFO - 

===== mean acc: 0.4331344460892544 =====


2025-07-23 05:13:35,488 - __main__ - INFO - Loading model: meta-llama/Llama-3.1-8B
2025-07-23 05:13:43,129 - __main__ - INFO - Layers order: 29,30,28,26,18,16,17,24,6,20,22,4,19,15,25,27,23,7,8,0,3,13,10,5,14,21,1,12,2,9,11,31
2025-07-23 05:13:43,129 - __main__ - INFO - Num prune: 12
2025-07-23 05:13:43,131 - __main__ - INFO - Layers to remove: [29, 30, 28, 26, 18, 16, 17, 24, 6, 20, 22, 4]
2025-07-23 05:13:43,131 - __main__ - INFO - ====================================================================================================
2025-07-23 05:13:43,135 - evaluate_grasp - INFO - load dataset wikitext2
2025-07-23 05:15:12,111 - evaluate_grasp - INFO - wikitext2 322.00701904296875
2025-07-23 05:15:12,111 - evaluate_grasp - INFO - load dataset ptb
2025-07-23 05:15:38,547 - evaluate_grasp - INFO - ptb 300.58465576171875
2025-07-23 06:45:23,654 - evaluate_grasp - INFO - {'wikitext2': 322.00701904296875, 'ptb': 300.58465576171875, 'mathqa': {'acc': 0.21909547738693466, 'acc_stderr': 0.007572098697066916, 'acc_norm': 0.23417085427135678, 'acc_norm_stderr': 0.007752342577747439}, 'piqa': {'acc': 0.6213275299238302, 'acc_stderr': 0.011317163404516847, 'acc_norm': 0.6186071817192601, 'acc_norm_stderr': 0.01133285040652868}, 'hellaswag': {'acc': 0.33419637522405893, 'acc_stderr': 0.004707447244200626, 'acc_norm': 0.4062935670185222, 'acc_norm_stderr': 0.0049013686295334155}, 'winogrande': {'acc': np.float64(0.5880031570639306), 'acc_stderr': 0.013833112857645928}, 'arc_easy': {'acc': 0.42508417508417506, 'acc_stderr': 0.010143966195717842, 'acc_norm': 0.38762626262626265, 'acc_norm_stderr': 0.009997307914447608}, 'arc_challenge': {'acc': 0.23464163822525597, 'acc_stderr': 0.012383873560768668, 'acc_norm': 0.26535836177474403, 'acc_norm_stderr': 0.012902554762313966}, 'openbookqa': {'acc': 0.204, 'acc_stderr': 0.018039369104138663, 'acc_norm': 0.292, 'acc_norm_stderr': 0.020354375480530082}, 'boolq': {'acc': 0.5155963302752293, 'acc_stderr': 0.008740799550176545}, 'mean': np.float64(0.3927430853979269)}
2025-07-23 06:45:23,656 - evaluate_grasp - INFO - 

===== mean acc: 0.3927430853979269 =====


2025-07-23 06:45:27,740 - __main__ - INFO - Loading model: meta-llama/Llama-3.1-8B
2025-07-23 06:45:35,437 - __main__ - INFO - Layers order: 29,30,28,26,18,16,17,24,6,20,22,4,19,15,25,27,23,7,8,0,3,13,10,5,14,21,1,12,2,9,11,31
2025-07-23 06:45:35,438 - __main__ - INFO - Num prune: 14
2025-07-23 06:45:35,439 - __main__ - INFO - Layers to remove: [29, 30, 28, 26, 18, 16, 17, 24, 6, 20, 22, 4, 19, 15]
2025-07-23 06:45:35,439 - __main__ - INFO - ====================================================================================================
2025-07-23 06:45:35,440 - evaluate_grasp - INFO - load dataset wikitext2
2025-07-23 06:46:46,593 - evaluate_grasp - INFO - wikitext2 5741.1708984375
2025-07-23 06:46:46,593 - evaluate_grasp - INFO - load dataset ptb
2025-07-23 06:47:08,380 - evaluate_grasp - INFO - ptb 1938.8447265625
2025-07-23 08:12:11,311 - evaluate_grasp - INFO - {'wikitext2': 5741.1708984375, 'ptb': 1938.8447265625, 'mathqa': {'acc': 0.20770519262981574, 'acc_stderr': 0.007426217631188539, 'acc_norm': 0.22278056951423786, 'acc_norm_stderr': 0.007617475572803624}, 'piqa': {'acc': 0.5941240478781284, 'acc_stderr': 0.011457256809261782, 'acc_norm': 0.5603917301414582, 'acc_norm_stderr': 0.011580417248656577}, 'hellaswag': {'acc': 0.3018323043218482, 'acc_stderr': 0.004581147247963199, 'acc_norm': 0.34993029277036447, 'acc_norm_stderr': 0.00475972926794319}, 'winogrande': {'acc': np.float64(0.5469613259668509), 'acc_stderr': 0.013990366632148088}, 'arc_easy': {'acc': 0.3383838383838384, 'acc_stderr': 0.009709034670525096, 'acc_norm': 0.3261784511784512, 'acc_norm_stderr': 0.009619849417035168}, 'arc_challenge': {'acc': 0.20819112627986347, 'acc_stderr': 0.011864866118448069, 'acc_norm': 0.24914675767918087, 'acc_norm_stderr': 0.012639407111926433}, 'openbookqa': {'acc': 0.156, 'acc_stderr': 0.016243636028391104, 'acc_norm': 0.278, 'acc_norm_stderr': 0.020055833888070907}, 'boolq': {'acc': 0.6134556574923548, 'acc_stderr': 0.008516943934341971}, 'mean': np.float64(0.37083168661908755)}
2025-07-23 08:12:11,313 - evaluate_grasp - INFO - 

===== mean acc: 0.37083168661908755 =====


2025-07-23 08:12:15,566 - __main__ - INFO - Loading model: meta-llama/Llama-3.1-8B
2025-07-23 08:12:23,662 - __main__ - INFO - Layers order: 29,30,28,26,18,16,17,24,6,20,22,4,19,15,25,27,23,7,8,0,3,13,10,5,14,21,1,12,2,9,11,31
2025-07-23 08:12:23,662 - __main__ - INFO - Num prune: 16
2025-07-23 08:12:23,664 - __main__ - INFO - Layers to remove: [29, 30, 28, 26, 18, 16, 17, 24, 6, 20, 22, 4, 19, 15, 25, 27]
2025-07-23 08:12:23,664 - __main__ - INFO - ====================================================================================================
2025-07-23 08:12:23,667 - evaluate_grasp - INFO - load dataset wikitext2
2025-07-23 08:13:36,961 - evaluate_grasp - INFO - wikitext2 18591.869140625
2025-07-23 08:13:36,961 - evaluate_grasp - INFO - load dataset ptb
2025-07-23 08:13:56,785 - evaluate_grasp - INFO - ptb 10137.1171875
2025-07-23 09:14:20,638 - evaluate_grasp - INFO - {'wikitext2': 18591.869140625, 'ptb': 10137.1171875, 'mathqa': {'acc': 0.19396984924623115, 'acc_stderr': 0.007238412826802101, 'acc_norm': 0.20402010050251257, 'acc_norm_stderr': 0.0073771416005697235}, 'piqa': {'acc': 0.5174102285092492, 'acc_stderr': 0.011658749823107691, 'acc_norm': 0.5054406964091404, 'acc_norm_stderr': 0.01166513350063706}, 'hellaswag': {'acc': 0.23471420035849433, 'acc_stderr': 0.004229538929090428, 'acc_norm': 0.20274845648277234, 'acc_norm_stderr': 0.004012249939174915}, 'winogrande': {'acc': np.float64(0.526440410418311), 'acc_stderr': 0.014032823874407225}, 'arc_easy': {'acc': 0.2718855218855219, 'acc_stderr': 0.009129795867310496, 'acc_norm': 0.27525252525252525, 'acc_norm_stderr': 0.009164888895174743}, 'arc_challenge': {'acc': 0.21928327645051193, 'acc_stderr': 0.012091245787615725, 'acc_norm': 0.25341296928327645, 'acc_norm_stderr': 0.012710896778378606}, 'openbookqa': {'acc': 0.164, 'acc_stderr': 0.016575811142446686, 'acc_norm': 0.28, 'acc_norm_stderr': 0.020099950647503237}, 'boolq': {'acc': 0.5434250764525994, 'acc_stderr': 0.008712010793695305}, 'mean': np.float64(0.3338910704151149)}
2025-07-23 09:14:20,640 - evaluate_grasp - INFO - 

===== mean acc: 0.3338910704151149 =====


