2025-07-23 09:53:51,538 - __main__ - INFO - Loading model: meta-llama/Llama-3.1-8B
2025-07-23 09:53:58,644 - __main__ - INFO - Layers order: 29,30,27,26,20,16,13,25,15,19,18,17,23,14,24,21,12,5,4,8,2,3,0,1,7,10,6,11,9,22,28,31
2025-07-23 09:53:58,644 - __main__ - INFO - Num prune: 4
2025-07-23 09:53:58,645 - __main__ - INFO - Layers to remove: [29, 30, 27, 26]
2025-07-23 09:53:58,645 - __main__ - INFO - ====================================================================================================
2025-07-23 09:53:58,649 - evaluate_grasp - INFO - load dataset wikitext2
2025-07-23 09:54:46,409 - evaluate_grasp - INFO - wikitext2 31.695859909057617
2025-07-23 09:54:46,410 - evaluate_grasp - INFO - load dataset ptb
2025-07-23 09:55:00,964 - evaluate_grasp - INFO - ptb 44.452022552490234
2025-07-23 12:26:37,413 - evaluate_grasp - INFO - {'wikitext2': 31.695859909057617, 'ptb': 44.452022552490234, 'mathqa': {'acc': 0.3336683417085427, 'acc_stderr': 0.008631838693226234, 'acc_norm': 0.33869346733668343, 'acc_norm_stderr': 0.008663739930566806}, 'piqa': {'acc': 0.7383025027203483, 'acc_stderr': 0.010255630772708232, 'acc_norm': 0.7431991294885746, 'acc_norm_stderr': 0.010192864802278039}, 'hellaswag': {'acc': 0.45269866560446126, 'acc_stderr': 0.004967402792744856, 'acc_norm': 0.630053774148576, 'acc_norm_stderr': 0.004818031396138912}, 'winogrande': {'acc': np.float64(0.6716653512233622), 'acc_stderr': 0.01319829944971789}, 'arc_easy': {'acc': 0.6367845117845118, 'acc_stderr': 0.0098683971361188, 'acc_norm': 0.6174242424242424, 'acc_norm_stderr': 0.00997283779053148}, 'arc_challenge': {'acc': 0.38139931740614336, 'acc_stderr': 0.014194389086685272, 'acc_norm': 0.41723549488054607, 'acc_norm_stderr': 0.014409825518403079}, 'openbookqa': {'acc': 0.284, 'acc_stderr': 0.020186703693570854, 'acc_norm': 0.418, 'acc_norm_stderr': 0.022080014812228137}, 'boolq': {'acc': 0.6232415902140673, 'acc_stderr': 0.008475244400491421}, 'mean': np.float64(0.5152200350826796)}
2025-07-23 12:26:37,415 - evaluate_grasp - INFO - 

===== mean acc: 0.5152200350826796 =====


2025-07-23 12:26:41,570 - __main__ - INFO - Loading model: meta-llama/Llama-3.1-8B
2025-07-23 12:26:51,472 - __main__ - INFO - Layers order: 29,30,27,26,20,16,13,25,15,19,18,17,23,14,24,21,12,5,4,8,2,3,0,1,7,10,6,11,9,22,28,31
2025-07-23 12:26:51,472 - __main__ - INFO - Num prune: 6
2025-07-23 12:26:51,473 - __main__ - INFO - Layers to remove: [29, 30, 27, 26, 20, 16]
2025-07-23 12:26:51,473 - __main__ - INFO - ====================================================================================================
2025-07-23 12:26:51,476 - evaluate_grasp - INFO - load dataset wikitext2
2025-07-23 12:31:07,155 - evaluate_grasp - INFO - wikitext2 47.889923095703125
2025-07-23 12:31:07,155 - evaluate_grasp - INFO - load dataset ptb
2025-07-23 12:32:27,802 - evaluate_grasp - INFO - ptb 60.93129348754883
