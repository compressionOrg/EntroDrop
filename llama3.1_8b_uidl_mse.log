2025-07-23 11:15:07,873 - __main__ - INFO - Loading model: meta-llama/Llama-3.1-8B
2025-07-23 11:15:16,820 - __main__ - INFO - Layers order: 24,25,26,27,28,29,30,31,19,18,20,8,7,6,9,10,17,21,11,5,16,4,12,13,14,15,3,2,22,1,0,23
2025-07-23 11:15:16,821 - __main__ - INFO - Num prune: 10
2025-07-23 11:15:16,822 - __main__ - INFO - Layers to remove: [24, 25, 26, 27, 28, 29, 30, 31, 19, 18]
2025-07-23 11:15:16,822 - __main__ - INFO - ====================================================================================================
2025-07-23 11:15:16,824 - evaluate_grasp - INFO - load dataset wikitext2
2025-07-23 11:15:55,574 - evaluate_grasp - INFO - wikitext2 2361.334228515625
2025-07-23 11:15:55,575 - evaluate_grasp - INFO - load dataset ptb
2025-07-23 11:16:07,308 - evaluate_grasp - INFO - ptb 3350.9580078125
2025-07-23 12:45:27,160 - evaluate_grasp - INFO - {'wikitext2': 2361.334228515625, 'ptb': 3350.9580078125, 'mathqa': {'acc': 0.29246231155778896, 'acc_stderr': 0.008327417406106081, 'acc_norm': 0.28375209380234506, 'acc_norm_stderr': 0.00825280931665108}, 'piqa': {'acc': 0.6697497279651795, 'acc_stderr': 0.0109729471330063, 'acc_norm': 0.6561479869423286, 'acc_norm_stderr': 0.011082356277961393}, 'hellaswag': {'acc': 0.3791077474606652, 'acc_stderr': 0.004841734453506663, 'acc_norm': 0.4934276040629357, 'acc_norm_stderr': 0.004989350311751649}, 'winogrande': {'acc': np.float64(0.6069455406471981), 'acc_stderr': 0.013727276249108451}, 'arc_easy': {'acc': 0.5888047138047138, 'acc_stderr': 0.010096663811817681, 'acc_norm': 0.5643939393939394, 'acc_norm_stderr': 0.010174341733665224}, 'arc_challenge': {'acc': 0.34982935153583616, 'acc_stderr': 0.013936809212158287, 'acc_norm': 0.39419795221843, 'acc_norm_stderr': 0.014280522667467328}, 'openbookqa': {'acc': 0.296, 'acc_stderr': 0.020435342091896135, 'acc_norm': 0.378, 'acc_norm_stderr': 0.021706550824518184}, 'boolq': {'acc': 0.6220183486238532, 'acc_stderr': 0.008480656964585245}, 'mean': np.float64(0.47561471769940433)}
2025-07-23 12:45:27,161 - evaluate_grasp - INFO - 

===== mean acc: 0.47561471769940433 =====


2025-07-23 12:45:31,612 - __main__ - INFO - Loading model: meta-llama/Llama-3.1-8B
2025-07-23 12:45:40,297 - __main__ - INFO - Layers order: 24,25,26,27,28,29,30,31,19,18,20,8,7,6,9,10,17,21,11,5,16,4,12,13,14,15,3,2,22,1,0,23
2025-07-23 12:45:40,298 - __main__ - INFO - Num prune: 12
2025-07-23 12:45:40,299 - __main__ - INFO - Layers to remove: [24, 25, 26, 27, 28, 29, 30, 31, 19, 18, 20, 8]
2025-07-23 12:45:40,299 - __main__ - INFO - ====================================================================================================
2025-07-23 12:45:40,301 - evaluate_grasp - INFO - load dataset wikitext2
2025-07-23 12:46:39,343 - evaluate_grasp - INFO - wikitext2 4052.981689453125
2025-07-23 12:46:39,343 - evaluate_grasp - INFO - load dataset ptb
2025-07-23 12:46:57,856 - evaluate_grasp - INFO - ptb 5988.193359375
